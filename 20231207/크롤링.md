# 크롤링
#### 구버전
```python
import urllib.request as ur
import urllib.parse as up

url = 'https://series.naver.com/search/search.series'
values = {
    't':'all', 'fs':'ebook', 'q':'에이트'
}
params = up.urlencode(values)
url = url + '?' + params
response = ur.urlopen(url)

if response.getcode() == 200 :
    data = response.read()
    raw_data = data.decode('utf-8')
    print(raw_data)
```
- **웹 사이트에서 정보를 추출**
- *BeautifulSoup는 정확히는 스크래핑, Selenium이 크롤링*

## URL 요청
- 주로 requests 패키지를 이용
- 파라미터와 헤더를 통해 쿼리를 입력하거나 모바일 페이지 요청 가능
```python
import requests
url = 'https://movie.daum.net/search' # URL 링크
params = {
    'q':'서울의 봄#tab=all'
} # 파라미터

response = requests.get(url, params=params) # GET 방식으로 요청
response.status_code # 200이 출력되면 성공적으로 작동

raw_data = response.text # 응답을 가공 가능한 HTML 텍스트 형태로 변환
```

### 모바일 버전
```python
pc = {
    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'
} # PC 버전
mobile = {
    'User-Agent':'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Mobile Safari/537.36'
} # 모바일 버전

url = 'https://movie.daum.net/ranking/reservation'
response = requests.get(url, headers=moblie)
response.status_code, response.url # (200, 'https://movie.daum.net/ranking/reservation')
```

## 데이터 가공
- BeautifulSoup 패키지를 이용해 보다 쉽게 HTML요소를 다룰 수 있음
```python
from bs4 import BeautifulSoup

soup = BeautifulSoup(raw_data)
soup # HTML 텍스트를 정돈된 형태로 출력
```

### 태그명으로 찾기
```python
title = soup.title # title 태그 추출
title.string, title.text, title.get_text() # title 요소를 출력
# ('랭킹 | 다음영화', '랭킹 | 다음영화', '랭킹 | 다음영화')

soup.a # 첫번째 a태그를 추출
soup('a') # a태그 전체 추출

soup('a')[0] # 첫번째 a태그를 추출
```

### find 및 find_all로 찾기
```python

```