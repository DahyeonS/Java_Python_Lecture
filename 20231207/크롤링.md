# 크롤링
#### 구버전
```python
import urllib.request as ur
import urllib.parse as up

url = 'https://series.naver.com/search/search.series'
values = {
    't':'all', 'fs':'ebook', 'q':'에이트'
}
params = up.urlencode(values)
url = url + '?' + params
response = ur.urlopen(url)

if response.getcode() == 200 :
    data = response.read()
    raw_data = data.decode('utf-8')
    print(raw_data)
```
- **웹 사이트에서 정보를 추출**
- *BeautifulSoup는 정확히는 스크래핑, Selenium이 크롤링*

## URL 요청
- 주로 requests 라이브러리를 이용
- 파라미터와 헤더를 통해 쿼리를 입력하거나 모바일 페이지 요청 가능
```python
import requests
url = 'https://movie.daum.net/search' # URL 링크
params = {
    'q':'서울의 봄#tab=all'
} # 파라미터

response = requests.get(url, params=params) # GET 방식으로 요청
response.status_code # 200이 출력되면 성공적으로 작동

raw_data = response.text # 응답을 가공 가능한 HTML 텍스트 형태로 변환
```

### 모바일 버전
```python
pc = {
    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'
} # PC 버전
mobile = {
    'User-Agent':'Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Mobile Safari/537.36'
} # 모바일 버전

url = 'https://movie.daum.net/ranking/reservation'
response = requests.get(url, headers=moblie)
```

## 데이터 가공
- BeautifulSoup 라이브러리를 이용해 보다 쉽게 HTML요소를 다룰 수 있음
```python
from bs4 import BeautifulSoup

soup = BeautifulSoup(raw_data)
soup # HTML 텍스트를 정돈된 형태로 출력
```

### 태그명으로 찾기
```python
title = soup.title # title 태그 추출
title.string, title.text, title.get_text() # title 요소를 출력
# ('랭킹 | 다음영화', '랭킹 | 다음영화', '랭킹 | 다음영화')

soup.a # 첫번째 a태그를 추출
soup('a') # a태그 전체 추출

first_a = soup('a')[0] # 첫번째 a태그를 추출
# <a href="#mainContent">본문 바로가기</a>
first_a.attrs['href'] # a 태그의 herf 요소를 추출
# '#mainContent'
```

### find 및 find_all로 찾기
- 특정 요소를 가진 태그를 추출 가능
```python
soup.find('a') # 첫번째 a태그를 추출
soup.find_all('a') # a태그 전체 추출

first_a = soup.find_all('a')[0] # <a href="#mainContent">본문 바로가기</a>
first_a.string, first_a.attrs['href'] # ('본문 바로가기', '#mainContent')

data = soup.find(class_='section_ranking')
hs = data.find(class_='head_section')

print(hs)
'''
<div class="head_section">
<h3 class="tit_section">예매순위</h3>
</div>
'''
hs.string, hs.text, hs.get_text() # (None, '\n예매순위\n', '\n예매순위\n')
```

#### 특정 클래스 추출
```python
# 첫번째 방법
link = soup.find(class_='direct-link') # 클래스가 direct-link인 태그 추출
a_list = link('a') # 해당 태그의 a태그 추출
a_list[0].attrs['href'], a_list[1].attrs['href'] # ('#mainContent', '#gnbContent')

# 두번째 방법
link = soup.find('div', attrs={'class':'direct-link'}) # 클래스가 direct-link인 div 추출
a_list = link('a') # 해당 div의 a태그 추출
a_list[0].attrs['href'], a_list[1].attrs['href'] # ('#mainContent', '#gnbContent')
```

## 데이터 저장
- 데이터를 dict 형태로 변환하여 피클 등의 파일로 저장 *(파일 저장 과정은 생략)*
```python
num = lis[0].find(class_='link_story').attrs['href'].split('movieId=')[1]
title = lis[0].find(class_='link_txt').text
grade = lis[0].find(class_='txt_grade').text
rate = lis[0].find_all(class_='txt_num')[0].text
date = lis[0].find_all(class_='txt_num')[1].text

print(f'번호: {num}, 영화이름: {title}, 평점: {grade}, 예매율: {rate}, 개봉일자: {date}')
# 번호: 156628, 영화이름: 서울의 봄, 평점: 9.5, 예매율: 51.6%, 개봉일자: 23.11.22
print({num:(title,grade,rate,date)})
# {'156628': ('서울의 봄', '9.5', '51.6%', '23.11.22')}
```
```python
m = movies[0]
link_txt = m.find('a', attrs={'class':'link_txt'})

mid = link_txt.attrs['href'].split('=')[1] # 영화 ID
title = link_txt.string # 영화 제목

txt_append = m.find('span', attrs={'class':'txt_append'})
grade = txt_append.find(attrs={'class':'txt_grade'}).string # 평점
rate = txt_append.find(attrs={'class':'txt_num'}).string # 예매율

txt_info = m.find('span', attrs={'class':'txt_info'}) 
open_date = txt_info.find('span', attrs={'class':'txt_num'}).string # 개봉일

{mid:(title, grade, rate, open_date)} # {'156628': ('서울의 봄', '9.5', '56.5%', '23.11.22')}
```
```python
mid_list = []
title_list = []
grade_list = []
rate_list = []
open_date_list = []

for m in movies :
    link_txt = m.find('a', attrs={'class':'link_txt'})
    
    # 영화 ID, 영화 제목
    mid = link_txt.attrs['href'].split('=')[1]
    title = link_txt.string
    
    # 평점, 예매율
    txt_append = m.find('span', attrs={'class':'txt_append'})
    grade = txt_append.find(attrs={'class':'txt_grade'}).string
    rate = txt_append.find(attrs={'class':'txt_num'}).string
    
    # 개봉일
    txt_info = m.find('span', attrs={'class':'txt_info'})
    open_date = txt_info.find('span', attrs={'class':'txt_num'}).string

    mid_list.append(mid)
    title_list.append(title)
    grade_list.append(grade)
    rate_list.append(rate)
    open_date_list.append(open_date)

minfo = list(zip(title_list, grade_list, rate_list, open_date_list))
minfos = list(zip(mid_list, minfo))
final_minfos = dict(minfos) # 데이터를 보내거나 파일로 저장 가능
```